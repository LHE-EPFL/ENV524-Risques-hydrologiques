{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b06b80b-70d6-4305-be77-37567943544d",
   "metadata": {},
   "source": [
    "# Séance 4 : Maximum de vraisemblance, inférence bayésienne & Metropolis-Hastings.\n",
    "### Professeur : Christophe Ancey\n",
    "#### Assistants : \n",
    "- Yanan Chen\n",
    "- Sofi Farazande\n",
    "- Clemente Gotelli\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa143ad-d985-4a65-abb2-f6a8b3a7245c",
   "metadata": {},
   "source": [
    "## 1. Inférence bayésienne, présentation de la méthode\n",
    "\n",
    "Lors du dernier TD nous avons vu comment trouver les paramètres $\\theta$ d'une loi pour décrire au mieux $n$ observations $d_i$. Les méthodes employées étaient la méthode des moments qui ajuste les moments des données à ceux de la loi et celle du maximum de vraisemblance qui consiste à maximiser Prob($d_1, d_2, \\cdots d_n \\left|\\right. \\theta$). Aujourd'hui nous allons voir une autre méthode basée sur le théorème de Bayes:\n",
    "\n",
    "$$ \n",
    "\\textrm{Prob}(\\theta| d)=\\frac{\\textrm{Prob}({d}|\\theta) \\textrm{Prob}(\\theta)}{\\int  \\textrm{Prob}(d|. \\theta) d \\theta}\n",
    "$$\n",
    "\n",
    "En d'autres termes, la probabilité  que les paramètres soient $\\theta$ est proportionnelle à la vraisemblance $\\textrm{Prob}({d}|. \\theta)$ pondérée par $\\textrm{Prob}(\\theta)$. $\\textrm{Prob}(\\theta)$ est la probabilité à priori d'avoir $\\theta$, et est appelée le prior. Cette loi $\\textrm{Prob}(\\theta)$ est déduite d'une connaissance experte ou d'un précédent calage, si ni l'une ni l'autre de ces informations n'est disponible on utilise une loi uniforme.  \n",
    "L'algorithme d'Hastings-Metropolis permet de trouver quels paramètres $\\theta$ maximisent l'équation 1, pour cela on se promène sur $Q(\\theta)=\\textrm{Prob}(\\theta |{d})$ par sauts successifs. Si $Q(\\theta_{i+1}) \\geq Q(\\theta_{i})$ on accepte toujours le saut car on se dirige vers des vraisemblances plus élevées, dans le cas contraire on accepte le saut avec une certaine probabilité. Peu à peu, saut après saut, nous allons donc approcher des maxima de $Q(\\theta)$ sans pour autant avoir une probabilité nulle de redescendre (ce qui permet de sortir d'un éventuel maxima secondaire par exemple). Les sauts sont contrôlés par la loi de probabilité instrumentale que l'on note ici $q$ et que l'on va considérer, pour simplifier, comme symétrique (i.e. $q(\\theta_{i+1}|.\\theta_i)=q(\\theta_i|.\\theta_{i+1})=q(|\\theta_{i+1}-\\theta_i|)$). De manière plus explicite:\n",
    "1. On part d'un état $\\theta_0$.\n",
    "2. On tire une valeur candidate selon la loi $q(\\theta_{i+1}|\\theta_i)$.\n",
    "3. On définit un taux d'acceptation $r$ de la manière suivante:\n",
    "$$\n",
    "r=min\\left[\\frac{Q(\\theta_{i+1})}{Q(\\theta_{i})},1\\right]\n",
    "$$\n",
    "    A cette étape, on voit que l'intégrale se simplifie dans le quotient. Notons aussi que cette expression est plus complexe lorsque la loi de probabilité instrumentale n'est pas symétrique.\n",
    "4. On accepte les paramètres $\\theta_{i+1}$ (c'est-à-dire on fait le saut) avec une probabilité $r$.\n",
    "5. On répète la procédure jusqu'à convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b924b0-dbf8-4eb0-941d-45bb1a13fd8d",
   "metadata": {},
   "source": [
    "## 2. Algorithme d'Hastings-Metropolis\n",
    "1. Pour commencer, générez $N=20$ valeurs tirées aléatoirement selon une loi de poisson de paramètre $\\lambda=2$. Ces valeurs représentent les données sur lesquelles nous allons caler une loi de poisson et essayer de retrouver le paramètre $\\lambda=2$ utilisé pour générer ces valeurs. `[poissrnd]`\n",
    "2. Codez l'algorithme d'Hastings-Metropolis. Pour cela faîtes une boucle qui va de $1$ jusqu'a `nPas`, le nombre de sauts autorisé (p. ex. $3000$). A chaque itération $i$, calculez le nouveau candidat potentiel $\\theta_{p}$ ainsi que le paramètre d'acceptation $r$ correspondant. Comme loi instrumentale $q$, on prendra une loi normale d'espérance $\\theta_{i}$ et d'écart-type 0,01. Considérant que nous n'avons pas de connaissances a priori, le prior sera pris uniforme dans un premier temps (par exemple selon une loi U(0,100)). Pour éviter des erreurs numériques lors du calcul de $r$, utilisez la log-vraisemblance:  \n",
    "\n",
    "$$\n",
    "r=\\frac{Q(\\theta_{p})}{Q(\\theta_{i})}= \\exp\\left[ l(\\theta_{p})+\\ln \\textrm{Prob}(\\theta_{p})-l(\\theta_{i})-\\ln \\textrm{Prob}(\\theta_{i})\\right]\n",
    "$$\n",
    "\n",
    "où $l(\\theta)$ est la log-vraisemblance.  \n",
    "Une fois $\\theta_{p}$ déterminé et $r$ calculé en conséquence, il faut effectuer un test: si $r \\geq 1$ on accepte dans tous les cas la nouvelle position (car on monte) et $\\theta_{i+1}=\\theta_{p}$, sinon on accepte  $\\theta_{i+1}$ avec une probabilité $r$ uniquement. Pour coder le taux d'acceptation $r<1$ on procède de la manière suivante: on tire une valeur aléatoire $u$ d'une distribution uniforme (cela se fait facilement dans Matlab avec la commande `rand`); si $r>u$ alors on accepte  $\\theta_{p}$, si $r<u$ on reste sur la position $\\theta_{i}$.  \n",
    "3. A chaque itération, enregistrez la position $\\theta_{i}$ dans un vecteur ${D_{0}}$, lorsque les $nPas$ sont effectués faites un graph de ce vecteur et calculez la moyenne de celui-ci (restreignez cette moyenne à la partie convergente du vecteur, par exemple les $1500$ derniers points).  \n",
    "4. Comparez le résultat obtenu avec ce que l'on obtient en utilisant la commande Matlab `poissfit` sur le même set de donnée.  \n",
    "5. Introduisez à présent un prior de type gaussien centré en $2$ et d'écart type 0,1. Calculez ensuite le vecteur ${D}$ correspondant et superposez sur un graph ${D}$ et ${D_{0}}$, qu'observez-vous ?  \n",
    "6. Changez $N$, augmentez le à une valeur supérieur (par exemple $100$) et refaites cette comparaison (prior uniforme vs prior centré en $2$); augmentez encore $N$ à $200$, que remarquez-vous?  \n",
    "7.  Introduisez un prior de type gaussien centré en 0,5 et d'écart type 0,1. Que constatez-vous pour $N=20,100,200$? Faîtes la même chose pour un prior complètement erroné (par exemple centré en $5$ et d'écart type $1$), que constatez-vous pour $N=20,100,200$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c484e4b-2462-4f28-b064-cb530ddb5351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
